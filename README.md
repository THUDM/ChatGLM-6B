# ChatGLM-6B

<p align="center">
   ğŸŒ <a href="https://chatglm.cn/blog" target="_blank">Blog</a> â€¢ ğŸ¤— <a href="https://huggingface.co/THUDM/chatglm-6b" target="_blank">HF Repo</a> â€¢ ğŸ¦ <a href="https://twitter.com/thukeg" target="_blank">Twitter</a> â€¢ ğŸ“ƒ <a href="https://arxiv.org/abs/2103.10360" target="_blank">[GLM@ACL 22]</a> <a href="https://github.com/THUDM/GLM" target="_blank">[GitHub]</a> â€¢ ğŸ“ƒ <a href="https://arxiv.org/abs/2210.02414" target="_blank">[GLM-130B@ICLR 23]</a> <a href="https://github.com/THUDM/GLM-130B" target="_blank">[GitHub]</a> <br>
</p>
<p align="center">
    ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ <a href="https://join.slack.com/t/chatglm/shared_invite/zt-1th2q5u69-7tURzFuOPanmuHy9hsZnKA" target="_blank">Slack</a> å’Œ <a href="resources/WECHAT.md" target="_blank">WeChat</a>
</p>

## ä»‹ç»

ChatGLM-6B æ˜¯ä¸€ä¸ªå¼€æºçš„ã€æ”¯æŒä¸­è‹±åŒè¯­çš„å¯¹è¯è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº [General Language Model (GLM)](https://github.com/THUDM/GLM) æ¶æ„ï¼Œå…·æœ‰ 62 äº¿å‚æ•°ã€‚ç»“åˆæ¨¡å‹é‡åŒ–æŠ€æœ¯ï¼Œç”¨æˆ·å¯ä»¥åœ¨æ¶ˆè´¹çº§çš„æ˜¾å¡ä¸Šè¿›è¡Œæœ¬åœ°éƒ¨ç½²ï¼ˆINT4 é‡åŒ–çº§åˆ«ä¸‹æœ€ä½åªéœ€ 6GB æ˜¾å­˜ï¼‰ã€‚
ChatGLM-6B ä½¿ç”¨äº†å’Œ ChatGPT ç›¸ä¼¼çš„æŠ€æœ¯ï¼Œé’ˆå¯¹ä¸­æ–‡é—®ç­”å’Œå¯¹è¯è¿›è¡Œäº†ä¼˜åŒ–ã€‚ç»è¿‡çº¦ 1T æ ‡è¯†ç¬¦çš„ä¸­è‹±åŒè¯­è®­ç»ƒï¼Œè¾…ä»¥ç›‘ç£å¾®è°ƒã€åé¦ˆè‡ªåŠ©ã€äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ç­‰æŠ€æœ¯çš„åŠ æŒï¼Œ62 äº¿å‚æ•°çš„ ChatGLM-6B å·²ç»èƒ½ç”Ÿæˆç›¸å½“ç¬¦åˆäººç±»åå¥½çš„å›ç­”ï¼Œæ›´å¤šä¿¡æ¯è¯·å‚è€ƒæˆ‘ä»¬çš„[åšå®¢](https://chatglm.cn/blog)ã€‚

ä¸ºäº†æ–¹ä¾¿ä¸‹æ¸¸å¼€å‘è€…é’ˆå¯¹è‡ªå·±çš„åº”ç”¨åœºæ™¯å®šåˆ¶æ¨¡å‹ï¼Œæˆ‘ä»¬åŒæ—¶å®ç°äº†åŸºäº [P-Tuning v2](https://github.com/THUDM/P-tuning-v2) çš„é«˜æ•ˆå‚æ•°å¾®è°ƒæ–¹æ³• [(ä½¿ç”¨æŒ‡å—)](ptuning/README.md) ï¼ŒINT4 é‡åŒ–çº§åˆ«ä¸‹æœ€ä½åªéœ€ 7GB æ˜¾å­˜å³å¯å¯åŠ¨å¾®è°ƒã€‚

ä¸è¿‡ï¼Œç”±äº ChatGLM-6B çš„è§„æ¨¡è¾ƒå°ï¼Œç›®å‰å·²çŸ¥å…¶å…·æœ‰ç›¸å½“å¤šçš„[**å±€é™æ€§**](#å±€é™æ€§)ï¼Œå¦‚äº‹å®æ€§/æ•°å­¦é€»è¾‘é”™è¯¯ï¼Œå¯èƒ½ç”Ÿæˆæœ‰å®³/æœ‰åè§å†…å®¹ï¼Œè¾ƒå¼±çš„ä¸Šä¸‹æ–‡èƒ½åŠ›ï¼Œè‡ªæˆ‘è®¤çŸ¥æ··ä¹±ï¼Œä»¥åŠå¯¹è‹±æ–‡æŒ‡ç¤ºç”Ÿæˆä¸ä¸­æ–‡æŒ‡ç¤ºå®Œå…¨çŸ›ç›¾çš„å†…å®¹ã€‚è¯·å¤§å®¶åœ¨ä½¿ç”¨å‰äº†è§£è¿™äº›é—®é¢˜ï¼Œä»¥å…äº§ç”Ÿè¯¯è§£ã€‚æ›´å¤§çš„åŸºäº 1300 äº¿å‚æ•° [GLM-130B](https://github.com/THUDM/GLM-130B) çš„ ChatGLM æ­£åœ¨å†…æµ‹å¼€å‘ä¸­ã€‚

*Read this in [English](README_en.md).*

## å‹æƒ…é“¾æ¥
å¯¹ ChatGLM è¿›è¡ŒåŠ é€Ÿçš„å¼€æºé¡¹ç›®ï¼š
* [ChatGLM-MNN](https://github.com/wangzhaode/ChatGLM-MNN): ä¸€ä¸ªåŸºäº MNN çš„ ChatGLM-6B C++ æ¨ç†å®ç°ï¼Œæ”¯æŒæ ¹æ®æ˜¾å­˜å¤§å°è‡ªåŠ¨åˆ†é…è®¡ç®—ä»»åŠ¡ç»™ GPU å’Œ CPU
* [JittorLLMs](https://github.com/Jittor/JittorLLMs)ï¼šæœ€ä½3Gæ˜¾å­˜æˆ–è€…æ²¡æœ‰æ˜¾å¡éƒ½å¯è¿è¡Œ ChatGLM-6B FP16ï¼Œ æ”¯æŒLinuxã€windowsã€Macéƒ¨ç½²

åŸºäºæˆ–ä½¿ç”¨äº† ChatGLM-6B çš„å¼€æºé¡¹ç›®ï¼š
* [langchain-ChatGLM](https://github.com/imClumsyPanda/langchain-ChatGLM)ï¼šåŸºäº langchain çš„ ChatGLM åº”ç”¨ï¼Œå®ç°åŸºäºå¯æ‰©å±•çŸ¥è¯†åº“çš„é—®ç­”
* [é—»è¾¾](https://github.com/l15y/wenda)ï¼šå¤§å‹è¯­è¨€æ¨¡å‹è°ƒç”¨å¹³å°ï¼ŒåŸºäº ChatGLM-6B å®ç°äº†ç±» ChatPDF åŠŸèƒ½
* [chatgpt_academic](https://github.com/binary-husky/chatgpt_academic): æ”¯æŒChatGLM-6Bçš„å­¦æœ¯å†™ä½œä¸ç¼–ç¨‹å·¥å…·ç®±ï¼Œå…·æœ‰æ¨¡å—åŒ–å’Œå¤šçº¿ç¨‹è°ƒç”¨LLMçš„ç‰¹ç‚¹ï¼Œå¯å¹¶è¡Œè°ƒç”¨å¤šç§LLMã€‚
* [glm-bot](https://github.com/initialencounter/glm-bot)ï¼šå°†ChatGLMæ¥å…¥Koishiå¯åœ¨å„å¤§èŠå¤©å¹³å°ä¸Šè°ƒç”¨ChatGLM

æ”¯æŒ ChatGLM-6B å’Œç›¸å…³åº”ç”¨åœ¨çº¿è®­ç»ƒçš„ç¤ºä¾‹é¡¹ç›®ï¼š
* [ChatGLM-6B çš„éƒ¨ç½²ä¸å¾®è°ƒæ•™ç¨‹](https://www.heywhale.com/mw/project/6436d82948f7da1fee2be59e)
* [ChatGLM-6B ç»“åˆ langchain å®ç°æœ¬åœ°çŸ¥è¯†åº“ QA Bot](https://www.heywhale.com/mw/project/643977aa446c45f4592a1e59)

ç¬¬ä¸‰æ–¹è¯„æµ‹ï¼š
* [Measuring Massive Multitask Chinese Understanding](https://arxiv.org/abs/2304.12986)

æ›´å¤šå¼€æºé¡¹ç›®å‚è§ [PROJECT.md](PROJECT.md)

## ä½¿ç”¨æ–¹å¼

### ç¡¬ä»¶éœ€æ±‚

| **é‡åŒ–ç­‰çº§**   | **æœ€ä½ GPU æ˜¾å­˜**ï¼ˆæ¨ç†ï¼‰ | **æœ€ä½ GPU æ˜¾å­˜**ï¼ˆé«˜æ•ˆå‚æ•°å¾®è°ƒï¼‰ |
| -------------- | ------------------------- | --------------------------------- |
| FP16ï¼ˆæ— é‡åŒ–ï¼‰ | 13 GB                     | 14 GB                             |
| INT8           | 8 GB                     | 9 GB                             |
| INT4           | 6 GB                      | 7 GB                              |
### ç¯å¢ƒå®‰è£…

ä½¿ç”¨ pip å®‰è£…ä¾èµ–ï¼š`pip install -r requirements.txt`ï¼Œå…¶ä¸­ `transformers` åº“ç‰ˆæœ¬æ¨èä¸º `4.27.1`ï¼Œä½†ç†è®ºä¸Šä¸ä½äº `4.23.1` å³å¯ã€‚

æ­¤å¤–ï¼Œå¦‚æœéœ€è¦åœ¨ cpu ä¸Šè¿è¡Œé‡åŒ–åçš„æ¨¡å‹ï¼Œè¿˜éœ€è¦å®‰è£… `gcc` ä¸ `openmp`ã€‚å¤šæ•° Linux å‘è¡Œç‰ˆé»˜è®¤å·²å®‰è£…ã€‚å¯¹äº Windows ï¼Œå¯åœ¨å®‰è£… [TDM-GCC](https://jmeubank.github.io/tdm-gcc/) æ—¶å‹¾é€‰ `openmp`ã€‚ Windows æµ‹è¯•ç¯å¢ƒ `gcc` ç‰ˆæœ¬ä¸º `TDM-GCC 10.3.0`ï¼Œ Linux ä¸º `gcc 11.3.0`ã€‚

### ä»£ç è°ƒç”¨ 

å¯ä»¥é€šè¿‡å¦‚ä¸‹ä»£ç è°ƒç”¨ ChatGLM-6B æ¨¡å‹æ¥ç”Ÿæˆå¯¹è¯ï¼š

```python
>>> from transformers import AutoTokenizer, AutoModel
>>> tokenizer = AutoTokenizer.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True)
>>> model = AutoModel.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True).half().cuda()
>>> model = model.eval()
>>> response, history = model.chat(tokenizer, "ä½ å¥½", history=[])
>>> print(response)
ä½ å¥½ğŸ‘‹!æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6B,å¾ˆé«˜å…´è§åˆ°ä½ ,æ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚
>>> response, history = model.chat(tokenizer, "æ™šä¸Šç¡ä¸ç€åº”è¯¥æ€ä¹ˆåŠ", history=history)
>>> print(response)
æ™šä¸Šç¡ä¸ç€å¯èƒ½ä¼šè®©ä½ æ„Ÿåˆ°ç„¦è™‘æˆ–ä¸èˆ’æœ,ä½†ä»¥ä¸‹æ˜¯ä¸€äº›å¯ä»¥å¸®åŠ©ä½ å…¥ç¡çš„æ–¹æ³•:

1. åˆ¶å®šè§„å¾‹çš„ç¡çœ æ—¶é—´è¡¨:ä¿æŒè§„å¾‹çš„ç¡çœ æ—¶é—´è¡¨å¯ä»¥å¸®åŠ©ä½ å»ºç«‹å¥åº·çš„ç¡çœ ä¹ æƒ¯,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚å°½é‡åœ¨æ¯å¤©çš„ç›¸åŒæ—¶é—´ä¸ŠåºŠ,å¹¶åœ¨åŒä¸€æ—¶é—´èµ·åºŠã€‚
2. åˆ›é€ ä¸€ä¸ªèˆ’é€‚çš„ç¡çœ ç¯å¢ƒ:ç¡®ä¿ç¡çœ ç¯å¢ƒèˆ’é€‚,å®‰é™,é»‘æš—ä¸”æ¸©åº¦é€‚å®œã€‚å¯ä»¥ä½¿ç”¨èˆ’é€‚çš„åºŠä¸Šç”¨å“,å¹¶ä¿æŒæˆ¿é—´é€šé£ã€‚
3. æ”¾æ¾èº«å¿ƒ:åœ¨ç¡å‰åšäº›æ”¾æ¾çš„æ´»åŠ¨,ä¾‹å¦‚æ³¡ä¸ªçƒ­æ°´æ¾¡,å¬äº›è½»æŸ”çš„éŸ³ä¹,é˜…è¯»ä¸€äº›æœ‰è¶£çš„ä¹¦ç±ç­‰,æœ‰åŠ©äºç¼“è§£ç´§å¼ å’Œç„¦è™‘,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚
4. é¿å…é¥®ç”¨å«æœ‰å’–å•¡å› çš„é¥®æ–™:å’–å•¡å› æ˜¯ä¸€ç§åˆºæ¿€æ€§ç‰©è´¨,ä¼šå½±å“ä½ çš„ç¡çœ è´¨é‡ã€‚å°½é‡é¿å…åœ¨ç¡å‰é¥®ç”¨å«æœ‰å’–å•¡å› çš„é¥®æ–™,ä¾‹å¦‚å’–å•¡,èŒ¶å’Œå¯ä¹ã€‚
5. é¿å…åœ¨åºŠä¸Šåšä¸ç¡çœ æ— å…³çš„äº‹æƒ…:åœ¨åºŠä¸Šåšäº›ä¸ç¡çœ æ— å…³çš„äº‹æƒ…,ä¾‹å¦‚çœ‹ç”µå½±,ç©æ¸¸æˆæˆ–å·¥ä½œç­‰,å¯èƒ½ä¼šå¹²æ‰°ä½ çš„ç¡çœ ã€‚
6. å°è¯•å‘¼å¸æŠ€å·§:æ·±å‘¼å¸æ˜¯ä¸€ç§æ”¾æ¾æŠ€å·§,å¯ä»¥å¸®åŠ©ä½ ç¼“è§£ç´§å¼ å’Œç„¦è™‘,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚è¯•ç€æ…¢æ…¢å¸æ°”,ä¿æŒå‡ ç§’é’Ÿ,ç„¶åç¼“æ…¢å‘¼æ°”ã€‚

å¦‚æœè¿™äº›æ–¹æ³•æ— æ³•å¸®åŠ©ä½ å…¥ç¡,ä½ å¯ä»¥è€ƒè™‘å’¨è¯¢åŒ»ç”Ÿæˆ–ç¡çœ ä¸“å®¶,å¯»æ±‚è¿›ä¸€æ­¥çš„å»ºè®®ã€‚
```
æ¨¡å‹çš„å®ç°ä»ç„¶å¤„åœ¨å˜åŠ¨ä¸­ã€‚å¦‚æœå¸Œæœ›å›ºå®šä½¿ç”¨çš„æ¨¡å‹å®ç°ä»¥ä¿è¯å…¼å®¹æ€§ï¼Œå¯ä»¥åœ¨ `from_pretrained` çš„è°ƒç”¨ä¸­å¢åŠ  `revision="v0.1.0"` å‚æ•°ã€‚`v0.1.0` æ˜¯å½“å‰æœ€æ–°çš„ç‰ˆæœ¬å·ï¼Œå®Œæ•´çš„ç‰ˆæœ¬åˆ—è¡¨å‚è§ [Change Log](https://huggingface.co/THUDM/chatglm-6b#change-log)ã€‚

### ä»æœ¬åœ°åŠ è½½æ¨¡å‹
ä»¥ä¸Šä»£ç ä¼šç”± `transformers` è‡ªåŠ¨ä¸‹è½½æ¨¡å‹å®ç°å’Œå‚æ•°ã€‚å®Œæ•´çš„æ¨¡å‹å®ç°å¯ä»¥åœ¨ [Hugging Face Hub](https://huggingface.co/THUDM/chatglm-6b)ã€‚å¦‚æœä½ çš„ç½‘ç»œç¯å¢ƒè¾ƒå·®ï¼Œä¸‹è½½æ¨¡å‹å‚æ•°å¯èƒ½ä¼šèŠ±è´¹è¾ƒé•¿æ—¶é—´ç”šè‡³å¤±è´¥ã€‚æ­¤æ—¶å¯ä»¥å…ˆå°†æ¨¡å‹ä¸‹è½½åˆ°æœ¬åœ°ï¼Œç„¶åä»æœ¬åœ°åŠ è½½ã€‚

ä» Hugging Face Hub ä¸‹è½½æ¨¡å‹éœ€è¦å…ˆ[å®‰è£…Git LFS](https://docs.github.com/zh/repositories/working-with-files/managing-large-files/installing-git-large-file-storage)ï¼Œç„¶åè¿è¡Œ
```Shell
git clone https://huggingface.co/THUDM/chatglm-6b
```

å¦‚æœä½ ä» Hugging Face Hub ä¸Šä¸‹è½½ checkpoint çš„é€Ÿåº¦è¾ƒæ…¢ï¼Œå¯ä»¥åªä¸‹è½½æ¨¡å‹å®ç°
```Shell
GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/THUDM/chatglm-6b
```
ç„¶åä»[è¿™é‡Œ](https://cloud.tsinghua.edu.cn/d/fb9f16d6dc8f482596c2/)æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹å‚æ•°æ–‡ä»¶ï¼Œå¹¶å°†ä¸‹è½½çš„æ–‡ä»¶æ›¿æ¢åˆ°æœ¬åœ°çš„ `chatglm-6b` ç›®å½•ä¸‹ã€‚

å°†æ¨¡å‹ä¸‹è½½åˆ°æœ¬åœ°ä¹‹åï¼Œå°†ä»¥ä¸Šä»£ç ä¸­çš„ `THUDM/chatglm-6b` æ›¿æ¢ä¸ºä½ æœ¬åœ°çš„ `chatglm-6b` æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå³å¯ä»æœ¬åœ°åŠ è½½æ¨¡å‹ã€‚

**Optional** æ¨¡å‹çš„å®ç°ä»ç„¶å¤„åœ¨å˜åŠ¨ä¸­ã€‚å¦‚æœå¸Œæœ›å›ºå®šä½¿ç”¨çš„æ¨¡å‹å®ç°ä»¥ä¿è¯å…¼å®¹æ€§ï¼Œå¯ä»¥æ‰§è¡Œ
```Shell
git checkout v0.1.0
```

## Demo & API

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªåŸºäº [Gradio](https://gradio.app) çš„ç½‘é¡µç‰ˆ Demo å’Œä¸€ä¸ªå‘½ä»¤è¡Œ Demoã€‚ä½¿ç”¨æ—¶é¦–å…ˆéœ€è¦ä¸‹è½½æœ¬ä»“åº“ï¼š

```shell
git clone https://github.com/THUDM/ChatGLM-6B
cd ChatGLM-6B
```

### ç½‘é¡µç‰ˆ Demo

![web-demo](resources/web-demo.gif)

é¦–å…ˆå®‰è£… Gradioï¼š`pip install gradio`ï¼Œç„¶åè¿è¡Œä»“åº“ä¸­çš„ [web_demo.py](web_demo.py)ï¼š 

```shell
python web_demo.py
```

ç¨‹åºä¼šè¿è¡Œä¸€ä¸ª Web Serverï¼Œå¹¶è¾“å‡ºåœ°å€ã€‚åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€è¾“å‡ºçš„åœ°å€å³å¯ä½¿ç”¨ã€‚æœ€æ–°ç‰ˆ Demo å®ç°äº†æ‰“å­—æœºæ•ˆæœï¼Œé€Ÿåº¦ä½“éªŒå¤§å¤§æå‡ã€‚æ³¨æ„ï¼Œç”±äºå›½å†… Gradio çš„ç½‘ç»œè®¿é—®è¾ƒä¸ºç¼“æ…¢ï¼Œå¯ç”¨ `demo.queue().launch(share=True, inbrowser=True)` æ—¶æ‰€æœ‰ç½‘ç»œä¼šç»è¿‡ Gradio æœåŠ¡å™¨è½¬å‘ï¼Œå¯¼è‡´æ‰“å­—æœºä½“éªŒå¤§å¹…ä¸‹é™ï¼Œç°åœ¨é»˜è®¤å¯åŠ¨æ–¹å¼å·²ç»æ”¹ä¸º `share=False`ï¼Œå¦‚æœ‰éœ€è¦å…¬ç½‘è®¿é—®çš„éœ€æ±‚ï¼Œå¯ä»¥é‡æ–°ä¿®æ”¹ä¸º `share=True` å¯åŠ¨ã€‚

æ„Ÿè°¢ [@AdamBear](https://github.com/AdamBear) å®ç°äº†åŸºäº Streamlit çš„ç½‘é¡µç‰ˆ Demoï¼Œè¿è¡Œæ–¹å¼è§[#117](https://github.com/THUDM/ChatGLM-6B/pull/117).

### å‘½ä»¤è¡Œ Demo

![cli-demo](resources/cli-demo.png)

è¿è¡Œä»“åº“ä¸­ [cli_demo.py](cli_demo.py)ï¼š

```shell
python cli_demo.py
```

ç¨‹åºä¼šåœ¨å‘½ä»¤è¡Œä¸­è¿›è¡Œäº¤äº’å¼çš„å¯¹è¯ï¼Œåœ¨å‘½ä»¤è¡Œä¸­è¾“å…¥æŒ‡ç¤ºå¹¶å›è½¦å³å¯ç”Ÿæˆå›å¤ï¼Œè¾“å…¥ `clear` å¯ä»¥æ¸…ç©ºå¯¹è¯å†å²ï¼Œè¾“å…¥ `stop` ç»ˆæ­¢ç¨‹åºã€‚

### APIéƒ¨ç½²
é¦–å…ˆéœ€è¦å®‰è£…é¢å¤–çš„ä¾èµ– `pip install fastapi uvicorn`ï¼Œç„¶åè¿è¡Œä»“åº“ä¸­çš„ [api.py](api.py)ï¼š
```shell
python api.py
```
é»˜è®¤éƒ¨ç½²åœ¨æœ¬åœ°çš„ 8000 ç«¯å£ï¼Œé€šè¿‡ POST æ–¹æ³•è¿›è¡Œè°ƒç”¨
```shell
curl -X POST "http://127.0.0.1:8000" \
     -H 'Content-Type: application/json' \
     -d '{"prompt": "ä½ å¥½", "history": []}'
```
å¾—åˆ°çš„è¿”å›å€¼ä¸º
```shell
{
  "response":"ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚",
  "history":[["ä½ å¥½","ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚"]],
  "status":200,
  "time":"2023-03-23 21:38:40"
}
```

## ä½æˆæœ¬éƒ¨ç½²
### æ¨¡å‹é‡åŒ–
é»˜è®¤æƒ…å†µä¸‹ï¼Œæ¨¡å‹ä»¥ FP16 ç²¾åº¦åŠ è½½ï¼Œè¿è¡Œä¸Šè¿°ä»£ç éœ€è¦å¤§æ¦‚ 13GB æ˜¾å­˜ã€‚å¦‚æœä½ çš„ GPU æ˜¾å­˜æœ‰é™ï¼Œå¯ä»¥å°è¯•ä»¥é‡åŒ–æ–¹å¼åŠ è½½æ¨¡å‹ï¼Œä½¿ç”¨æ–¹æ³•å¦‚ä¸‹ï¼š

```python
# æŒ‰éœ€ä¿®æ”¹ï¼Œç›®å‰åªæ”¯æŒ 4/8 bit é‡åŒ–
model = AutoModel.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True).quantize(8).half().cuda()
```

è¿›è¡Œ 2 è‡³ 3 è½®å¯¹è¯åï¼Œ8-bit é‡åŒ–ä¸‹ GPU æ˜¾å­˜å ç”¨çº¦ä¸º 10GBï¼Œ4-bit é‡åŒ–ä¸‹ä»…éœ€ 6GB å ç”¨ã€‚éšç€å¯¹è¯è½®æ•°çš„å¢å¤šï¼Œå¯¹åº”æ¶ˆè€—æ˜¾å­˜ä¹Ÿéšä¹‹å¢é•¿ï¼Œç”±äºé‡‡ç”¨äº†ç›¸å¯¹ä½ç½®ç¼–ç ï¼Œç†è®ºä¸Š ChatGLM-6B æ”¯æŒæ— é™é•¿çš„ context-lengthï¼Œä½†æ€»é•¿åº¦è¶…è¿‡ 2048ï¼ˆè®­ç»ƒé•¿åº¦ï¼‰åæ€§èƒ½ä¼šé€æ¸ä¸‹é™ã€‚

æ¨¡å‹é‡åŒ–ä¼šå¸¦æ¥ä¸€å®šçš„æ€§èƒ½æŸå¤±ï¼Œç»è¿‡æµ‹è¯•ï¼ŒChatGLM-6B åœ¨ 4-bit é‡åŒ–ä¸‹ä»ç„¶èƒ½å¤Ÿè¿›è¡Œè‡ªç„¶æµç•…çš„ç”Ÿæˆã€‚ä½¿ç”¨ [GPT-Q](https://arxiv.org/abs/2210.17323) ç­‰é‡åŒ–æ–¹æ¡ˆå¯ä»¥è¿›ä¸€æ­¥å‹ç¼©é‡åŒ–ç²¾åº¦/æå‡ç›¸åŒé‡åŒ–ç²¾åº¦ä¸‹çš„æ¨¡å‹æ€§èƒ½ï¼Œæ¬¢è¿å¤§å®¶æå‡ºå¯¹åº”çš„ Pull Requestã€‚

é‡åŒ–è¿‡ç¨‹éœ€è¦åœ¨å†…å­˜ä¸­é¦–å…ˆåŠ è½½ FP16 æ ¼å¼çš„æ¨¡å‹ï¼Œæ¶ˆè€—å¤§æ¦‚ 13GB çš„å†…å­˜ã€‚å¦‚æœä½ çš„å†…å­˜ä¸è¶³çš„è¯ï¼Œå¯ä»¥ç›´æ¥åŠ è½½é‡åŒ–åçš„æ¨¡å‹ï¼ŒINT4 é‡åŒ–åçš„æ¨¡å‹ä»…éœ€å¤§æ¦‚ 5.2GB çš„å†…å­˜ï¼š
```python
# INT8 é‡åŒ–çš„æ¨¡å‹å°†"THUDM/chatglm-6b-int4"æ”¹ä¸º"THUDM/chatglm-6b-int8"
model = AutoModel.from_pretrained("THUDM/chatglm-6b-int4", trust_remote_code=True).half().cuda()
```
é‡åŒ–æ¨¡å‹çš„å‚æ•°æ–‡ä»¶ä¹Ÿå¯ä»¥ä»[è¿™é‡Œ](https://cloud.tsinghua.edu.cn/d/674208019e314311ab5c/)æ‰‹åŠ¨ä¸‹è½½ã€‚

### CPU éƒ¨ç½²
å¦‚æœä½ æ²¡æœ‰ GPU ç¡¬ä»¶çš„è¯ï¼Œä¹Ÿå¯ä»¥åœ¨ CPU ä¸Šè¿›è¡Œæ¨ç†ï¼Œä½†æ˜¯æ¨ç†é€Ÿåº¦ä¼šæ›´æ…¢ã€‚ä½¿ç”¨æ–¹æ³•å¦‚ä¸‹ï¼ˆéœ€è¦å¤§æ¦‚ 32GB å†…å­˜ï¼‰
```python
model = AutoModel.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True).float()
```

å¦‚æœä½ çš„å†…å­˜ä¸è¶³ï¼Œå¯ä»¥ç›´æ¥åŠ è½½é‡åŒ–åçš„æ¨¡å‹ï¼š
```python
# INT8 é‡åŒ–çš„æ¨¡å‹å°†"THUDM/chatglm-6b-int4"æ”¹ä¸º"THUDM/chatglm-6b-int8"
model = AutoModel.from_pretrained("THUDM/chatglm-6b-int4",trust_remote_code=True).float()
```

å¦‚æœé‡åˆ°äº†æŠ¥é”™ `Could not find module 'nvcuda.dll'` æˆ–è€… `RuntimeError: Unknown platform: darwin` (MacOS) ï¼Œè¯·[ä»æœ¬åœ°åŠ è½½æ¨¡å‹](README.md#ä»æœ¬åœ°åŠ è½½æ¨¡å‹)

### Mac ä¸Šçš„ CPU éƒ¨ç½²å’ŒåŠ é€Ÿ

Macç›´æ¥åŠ è½½é‡åŒ–åçš„æ¨¡å‹ä¼šå‡ºç°é—®é¢˜ï¼Œä¾‹å¦‚`clang: error: unsupported option '-fopenmp'ï¼Œè¿™æ˜¯ç”±äºMacç”±äºæœ¬èº«ç¼ºä¹ompå¯¼è‡´çš„ï¼Œæ­¤æ—¶å¯è¿è¡Œä½†æ˜¯å•æ ¸ã€‚

ä»¥[chatglm-6b-int4](https://huggingface.co/THUDM/chatglm-6b-int4)é‡åŒ–æ¨¡å‹ä¸ºä¾‹ï¼Œéœ€è¦åšå¦‚ä¸‹é…ç½®ï¼Œå³å¯åœ¨Macä¸‹ä½¿ç”¨OMPï¼š

#### ç¬¬ä¸€æ­¥ï¼šå®‰è£…`libomp`

```bash
# ç¬¬ä¸€æ­¥: å‚è€ƒ`https://mac.r-project.org/openmp/`
## å‡è®¾: gcc(clang)æ˜¯14.xç‰ˆæœ¬ï¼Œå…¶ä»–ç‰ˆæœ¬è§R-Projectæä¾›çš„è¡¨æ ¼
curl -O https://mac.r-project.org/openmp/openmp-14.0.6-darwin20-Release.tar.gz
sudo tar fvxz openmp-14.0.6-darwin20-Release.tar.gz -C /
```
æ­¤æ—¶ä¼šå®‰è£…ä¸‹é¢å‡ ä¸ªæ–‡ä»¶ï¼š`/usr/local/lib/libomp.dylib`, `/usr/local/include/ompt.h`, `/usr/local/include/omp.h`, `/usr/local/include/omp-tools.h`ã€‚

#### ç¬¬äºŒæ­¥ï¼šé…ç½®`gcc`ç¼–è¯‘é¡¹

ç„¶åé’ˆå¯¹`chatglm-6b-int4`, ä¿®æ”¹[quantization.py](https://huggingface.co/THUDM/chatglm-6b-int4/blob/main/quantization.py)ï¼Œä¸»è¦æ˜¯æŠŠç¡¬ç¼–ç çš„`gcc -O3 -fPIC -pthread -fopenmp -std=c99`å‘½ä»¤ä¿®æ”¹æˆ`gcc -O3 -fPIC -Xclang -fopenmp -pthread  -lomp -std=c99`ï¼Œ[å¯¹åº”ä»£ç ](https://huggingface.co/THUDM/chatglm-6b-int4/blob/63d66b0572d11cedd5574b38da720299599539b3/quantization.py#L168)è§ä¸‹:

```python
# ç¬¬äºŒæ­¥: æ‰¾åˆ°åŒ…å«`gcc -O3 -fPIC -pthread -fopenmp -std=c99`çš„è¿™ä¸€è¡Œï¼Œå¹¶ä¿®æ”¹æˆ
compile_command = "gcc -O3 -fPIC -Xclang -fopenmp -pthread  -lomp -std=c99 {} -shared -o {}".format(source_code, kernel_file)
```

> è¡¥å……è¯´æ˜ï¼šå¯ä»¥ç”¨`platform.uname()[0] == 'Darwin'`åšOSçš„åˆ¤æ–­ï¼Œä»è€Œä½¿å¾—[quantization.py](https://huggingface.co/THUDM/chatglm-6b-int4/blob/main/quantization.py)æœ‰å…¼å®¹æ€§ã€‚

> æ³¨æ„ï¼šå¦‚æœä½ ä¹‹å‰è¿è¡Œ`ChatGLM`é¡¹ç›®å¤±è´¥è¿‡ï¼Œæœ€å¥½æ¸…ä¸€ä¸‹Huggingfaceçš„ç¼“å­˜ï¼Œi.e. é»˜è®¤ä¸‹æ˜¯ `rm -rf ${HOME}/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4`ã€‚ç”±äºä½¿ç”¨äº†`rm`å‘½ä»¤ï¼Œè¯·æ˜ç¡®çŸ¥é“è‡ªå·±åœ¨åˆ é™¤ä»€ä¹ˆã€‚

### Mac ä¸Šçš„ GPU åŠ é€Ÿ
å¯¹äºæ­è½½äº†Apple Siliconçš„Macï¼ˆä»¥åŠMacBookï¼‰ï¼Œå¯ä»¥ä½¿ç”¨ MPS åç«¯æ¥åœ¨ GPU ä¸Šè¿è¡Œ ChatGLM-6Bã€‚éœ€è¦å‚è€ƒ Apple çš„ [å®˜æ–¹è¯´æ˜](https://developer.apple.com/metal/pytorch) å®‰è£… PyTorch-Nightlyã€‚

ç›®å‰åœ¨ MacOS ä¸Šåªæ”¯æŒ[ä»æœ¬åœ°åŠ è½½æ¨¡å‹](README.md#ä»æœ¬åœ°åŠ è½½æ¨¡å‹)ã€‚å°†ä»£ç ä¸­çš„æ¨¡å‹åŠ è½½æ”¹ä¸ºä»æœ¬åœ°åŠ è½½ï¼Œå¹¶ä½¿ç”¨ mps åç«¯ï¼š
```python
model = AutoModel.from_pretrained("your local path", trust_remote_code=True).half().to('mps')
```
å³å¯ä½¿ç”¨åœ¨ Mac ä¸Šä½¿ç”¨ GPU åŠ é€Ÿæ¨¡å‹æ¨ç†ã€‚å¦‚æœå‡ºç°å…³äº`half`çš„æŠ¥é”™ï¼ˆæ¯”å¦‚åœ¨MacOS 13.3.xä¸Šï¼‰ï¼Œå¯ä»¥æ”¹æˆï¼š
```python
model = AutoModel.from_pretrained("your local path", trust_remote_code=True).float().to('mps')
```

> æ³¨æ„ï¼šä¸Šè¿°æ–¹æ³•åœ¨éé‡åŒ–ç‰ˆä¸­ï¼Œè¿è¡Œæ²¡æœ‰é—®é¢˜ã€‚é‡åŒ–ç‰ˆæ¨¡å‹åœ¨MPSè®¾å¤‡è¿è¡Œå¯ä»¥å…³æ³¨[è¿™ä¸ª](https://github.com/THUDM/ChatGLM-6B/issues/462)ISSUEï¼Œè¿™ä¸»è¦æ˜¯[kernel](https://huggingface.co/THUDM/chatglm-6b/blob/658202d88ac4bb782b99e99ac3adff58b4d0b813/quantization.py#L27)çš„åŸå› ï¼Œå¯ä»¥è§£åŒ…è¿™ä¸ª`ELF`æ–‡ä»¶çœ‹åˆ°æ˜¯CUDAçš„å®ç°ã€‚

### å¤šå¡éƒ¨ç½²
å¦‚æœä½ æœ‰å¤šå¼  GPUï¼Œä½†æ˜¯æ¯å¼  GPU çš„æ˜¾å­˜å¤§å°éƒ½ä¸è¶³ä»¥å®¹çº³å®Œæ•´çš„æ¨¡å‹ï¼Œé‚£ä¹ˆå¯ä»¥å°†æ¨¡å‹åˆ‡åˆ†åœ¨å¤šå¼ GPUä¸Šã€‚é¦–å…ˆå®‰è£… accelerate: `pip install accelerate`ï¼Œç„¶åé€šè¿‡å¦‚ä¸‹æ–¹æ³•åŠ è½½æ¨¡å‹ï¼š
```python
from utils import load_model_on_gpus
model = load_model_on_gpus("THUDM/chatglm-6b", num_gpus=2)
```
å³å¯å°†æ¨¡å‹éƒ¨ç½²åˆ°ä¸¤å¼  GPU ä¸Šè¿›è¡Œæ¨ç†ã€‚ä½ å¯ä»¥å°† `num_gpus` æ”¹ä¸ºä½ å¸Œæœ›ä½¿ç”¨çš„ GPU æ•°ã€‚é»˜è®¤æ˜¯å‡åŒ€åˆ‡åˆ†çš„ï¼Œä½ ä¹Ÿå¯ä»¥ä¼ å…¥ `device_map` å‚æ•°æ¥è‡ªå·±æŒ‡å®šã€‚ 

## é«˜æ•ˆå‚æ•°å¾®è°ƒ
åŸºäº [P-tuning v2](https://github.com/THUDM/P-tuning-v2) çš„é«˜æ•ˆå‚æ•°å¾®è°ƒã€‚å…·ä½“ä½¿ç”¨æ–¹æ³•è¯¦è§ [ptuning/README.md](ptuning/README.md)ã€‚

## æ›´æ–°ä¿¡æ¯
**[2023/04/16]** å¢åŠ  INT8 é‡åŒ–åçš„æ¨¡å‹ [ChatGLM-6B-INT8](https://huggingface.co/THUDM/chatglm-6b-int8)ã€‚å¢åŠ å¤šå¡éƒ¨ç½²ï¼ˆæ„Ÿè°¢ [@Cherrysaber](https://github.com/Cherrysaber)ï¼‰ã€‚

**[2023/04/06]** ä¼˜åŒ–web demoçš„ç•Œé¢ï¼ˆæ„Ÿè°¢ [@tuteng0915](https://github.com/tuteng0915)ï¼‰ã€‚ç§»é™¤embeddingä¸­çš„image tokenä»¥å‡å°æ˜¾å­˜å ç”¨ï¼ˆéœ€è¦æ›´æ–°æ¨¡å‹æ–‡ä»¶`pytorch_model-00001-of-00008.bin`å’Œ`pytorch_model-00008-of-00008.bin`ï¼Œæ„Ÿè°¢ [@silverriver](https://github.com/silverriver) æå‡ºçš„æƒ³æ³•ï¼‰ã€‚å»æ‰äº†å¯¹ `icetk` çš„ä¾èµ–ï¼ˆéœ€è¦æ›´æ–°æ¨¡å‹æ–‡ä»¶`ice_text.model`ï¼‰ã€‚

**[2023/03/31]** å¢åŠ åŸºäº [P-Tuning-v2](https://github.com/THUDM/P-tuning-v2) çš„é«˜æ•ˆå‚æ•°å¾®è°ƒå®ç°ï¼ŒINT4 é‡åŒ–çº§åˆ«ä¸‹æœ€ä½åªéœ€ 7GB æ˜¾å­˜å³å¯è¿›è¡Œæ¨¡å‹å¾®è°ƒã€‚è¯¦è§[é«˜æ•ˆå‚æ•°å¾®è°ƒæ–¹æ³•](ptuning/README.md)ã€‚

**[2023/03/23]** å¢åŠ  API éƒ¨ç½²ï¼ˆæ„Ÿè°¢ [@LemonQu-GIT](https://github.com/LemonQu-GIT)ï¼‰ã€‚å¢åŠ  Embedding é‡åŒ–æ¨¡å‹ [ChatGLM-6B-INT4-QE](https://huggingface.co/THUDM/chatglm-6b-int4-qe)ã€‚å¢åŠ é…å¤‡ Apple Silicon èŠ¯ç‰‡çš„ Mac ä¸Š GPU åŠ é€Ÿçš„æ”¯æŒã€‚

**[2023/03/19]** å¢åŠ æµå¼è¾“å‡ºæ¥å£ `stream_chat`ï¼Œå·²æ›´æ–°åˆ°ç½‘é¡µç‰ˆå’Œå‘½ä»¤è¡Œ Demoã€‚ä¿®å¤è¾“å‡ºä¸­çš„ä¸­æ–‡æ ‡ç‚¹ã€‚å¢åŠ  INT4 é‡åŒ–åçš„æ¨¡å‹ [ChatGLM-6B-INT4](https://huggingface.co/THUDM/chatglm-6b-int4)

## ChatGLM-6B ç¤ºä¾‹

ä»¥ä¸‹æ˜¯ä¸€äº›ä½¿ç”¨ `web_demo.py` å¾—åˆ°çš„ç¤ºä¾‹æˆªå›¾ã€‚æ›´å¤š ChatGLM-6B çš„å¯èƒ½ï¼Œç­‰å¾…ä½ æ¥æ¢ç´¢å‘ç°ï¼

<details><summary><b>è‡ªæˆ‘è®¤çŸ¥</b></summary>

![](examples/self-introduction.png)

</details>

<details><summary><b>æçº²å†™ä½œ</b></summary>

![](examples/blog-outline.png)

</details>

<details><summary><b>æ–‡æ¡ˆå†™ä½œ</b></summary>

![](examples/ad-writing-2.png)

![](examples/comments-writing.png)

</details>

<details><summary><b>é‚®ä»¶å†™ä½œåŠ©æ‰‹</b></summary>

![](examples/email-writing-1.png)

![](examples/email-writing-2.png)

</details>

<details><summary><b>ä¿¡æ¯æŠ½å–</b></summary>

![](examples/information-extraction.png)

</details>

<details><summary><b>è§’è‰²æ‰®æ¼”</b></summary>

![](examples/role-play.png)

</details>

<details><summary><b>è¯„è®ºæ¯”è¾ƒ</b></summary>

![](examples/sport.png)

</details>

<details><summary><b>æ—…æ¸¸å‘å¯¼</b></summary>

![](examples/tour-guide.png)

</details>

## å±€é™æ€§

ç”±äº ChatGLM-6B çš„å°è§„æ¨¡ï¼Œå…¶èƒ½åŠ›ä»ç„¶æœ‰è®¸å¤šå±€é™æ€§ã€‚ä»¥ä¸‹æ˜¯æˆ‘ä»¬ç›®å‰å‘ç°çš„ä¸€äº›é—®é¢˜ï¼š

- æ¨¡å‹å®¹é‡è¾ƒå°ï¼š6B çš„å°å®¹é‡ï¼Œå†³å®šäº†å…¶ç›¸å¯¹è¾ƒå¼±çš„æ¨¡å‹è®°å¿†å’Œè¯­è¨€èƒ½åŠ›ã€‚åœ¨é¢å¯¹è®¸å¤šäº‹å®æ€§çŸ¥è¯†ä»»åŠ¡æ—¶ï¼ŒChatGLM-6B å¯èƒ½ä¼šç”Ÿæˆä¸æ­£ç¡®çš„ä¿¡æ¯ï¼›å®ƒä¹Ÿä¸æ“…é•¿é€»è¾‘ç±»é—®é¢˜ï¼ˆå¦‚æ•°å­¦ã€ç¼–ç¨‹ï¼‰çš„è§£ç­”ã€‚
    <details><summary><b>ç‚¹å‡»æŸ¥çœ‹ä¾‹å­</b></summary>
    
    ![](limitations/factual_error.png)
    
    ![](limitations/math_error.png)
    
    </details>
  
- äº§ç”Ÿæœ‰å®³è¯´æ˜æˆ–æœ‰åè§çš„å†…å®¹ï¼šChatGLM-6B åªæ˜¯ä¸€ä¸ªåˆæ­¥ä¸äººç±»æ„å›¾å¯¹é½çš„è¯­è¨€æ¨¡å‹ï¼Œå¯èƒ½ä¼šç”Ÿæˆæœ‰å®³ã€æœ‰åè§çš„å†…å®¹ã€‚ï¼ˆå†…å®¹å¯èƒ½å…·æœ‰å†’çŠ¯æ€§ï¼Œæ­¤å¤„ä¸å±•ç¤ºï¼‰

- è‹±æ–‡èƒ½åŠ›ä¸è¶³ï¼šChatGLM-6B è®­ç»ƒæ—¶ä½¿ç”¨çš„æŒ‡ç¤º/å›ç­”å¤§éƒ¨åˆ†éƒ½æ˜¯ä¸­æ–‡çš„ï¼Œä»…æœ‰æå°ä¸€éƒ¨åˆ†è‹±æ–‡å†…å®¹ã€‚å› æ­¤ï¼Œå¦‚æœè¾“å…¥è‹±æ–‡æŒ‡ç¤ºï¼Œå›å¤çš„è´¨é‡è¿œä¸å¦‚ä¸­æ–‡ï¼Œç”šè‡³ä¸ä¸­æ–‡æŒ‡ç¤ºä¸‹çš„å†…å®¹çŸ›ç›¾ï¼Œå¹¶ä¸”å‡ºç°ä¸­è‹±å¤¹æ‚çš„æƒ…å†µã€‚

- æ˜“è¢«è¯¯å¯¼ï¼Œå¯¹è¯èƒ½åŠ›è¾ƒå¼±ï¼šChatGLM-6B å¯¹è¯èƒ½åŠ›è¿˜æ¯”è¾ƒå¼±ï¼Œè€Œä¸” â€œè‡ªæˆ‘è®¤çŸ¥â€ å­˜åœ¨é—®é¢˜ï¼Œå¹¶å¾ˆå®¹æ˜“è¢«è¯¯å¯¼å¹¶äº§ç”Ÿé”™è¯¯çš„è¨€è®ºã€‚ä¾‹å¦‚å½“å‰ç‰ˆæœ¬çš„æ¨¡å‹åœ¨è¢«è¯¯å¯¼çš„æƒ…å†µä¸‹ï¼Œä¼šåœ¨è‡ªæˆ‘è®¤çŸ¥ä¸Šå‘ç”Ÿåå·®ã€‚
    <details><summary><b>ç‚¹å‡»æŸ¥çœ‹ä¾‹å­</b></summary>

    ![](limitations/self-confusion_google.jpg)
    
    ![](limitations/self-confusion_openai.jpg)
    
    ![](limitations/self-confusion_tencent.jpg)
    
    </details>

## åè®®

æœ¬ä»“åº“çš„ä»£ç ä¾ç…§ [Apache-2.0](LICENSE) åè®®å¼€æºï¼ŒChatGLM-6B æ¨¡å‹çš„æƒé‡çš„ä½¿ç”¨åˆ™éœ€è¦éµå¾ª [Model License](MODEL_LICENSE)ã€‚

## å¼•ç”¨

å¦‚æœä½ è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œæœ‰å¸®åŠ©çš„è¯ï¼Œè¯·è€ƒè™‘å¼•ç”¨ä¸‹åˆ—è®ºæ–‡

```
@inproceedings{
  zeng2023glm-130b,
  title={{GLM}-130B: An Open Bilingual Pre-trained Model},
  author={Aohan Zeng and Xiao Liu and Zhengxiao Du and Zihan Wang and Hanyu Lai and Ming Ding and Zhuoyi Yang and Yifan Xu and Wendi Zheng and Xiao Xia and Weng Lam Tam and Zixuan Ma and Yufei Xue and Jidong Zhai and Wenguang Chen and Zhiyuan Liu and Peng Zhang and Yuxiao Dong and Jie Tang},
  booktitle={The Eleventh International Conference on Learning Representations (ICLR)},
  year={2023},
  url={https://openreview.net/forum?id=-Aw0rrrPUF}
}
```
```
@inproceedings{du2022glm,
  title={GLM: General Language Model Pretraining with Autoregressive Blank Infilling},
  author={Du, Zhengxiao and Qian, Yujie and Liu, Xiao and Ding, Ming and Qiu, Jiezhong and Yang, Zhilin and Tang, Jie},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={320--335},
  year={2022}
}
```
